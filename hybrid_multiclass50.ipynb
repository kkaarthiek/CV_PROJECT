{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "891526ba",
   "metadata": {},
   "source": [
    "# Hybrid (ResNet50 + SwinV2 Small) â€” Multiclass by Platform (Fake Images Only)\n",
    "\n",
    "This notebook fine-tunes a hybrid model that fuses torchvision ResNet18 and Hugging Face SwinV2 Small to classify fake images by their 'platform' field in metadata.json.\n",
    "\n",
    "Notes:\n",
    "- Filters the dataset to status == 'fake' and uses 'platform' as label.\n",
    "- Uses AutoImageProcessor for SwinV2 preprocessing and ImageNet normalization for ResNet.\n",
    "- Windows-friendly data loading (num_workers=0) and step logging enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33f3da8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\SEM5\\cv_project\\cv_train\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import evaluate\n",
    "\n",
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    Swinv2Model,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    EarlyStoppingCallback,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38f05b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch: 2.9.0+cu126 cuda available: True\n",
      "transformers: 4.57.1\n"
     ]
    }
   ],
   "source": [
    "# Environment check\n",
    "import transformers\n",
    "print('torch:', torch.__version__, 'cuda available:', torch.cuda.is_available())\n",
    "print('transformers:', transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "071bfc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata from: ./data\\metadata.json\n",
      "Classes (platforms): ['dall-E3', 'im', 'sd']\n",
      "Total: 7109 Train: 5687 Val: 1422\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>image_file</th>\n",
       "      <th>prompts</th>\n",
       "      <th>platform</th>\n",
       "      <th>status</th>\n",
       "      <th>full_path</th>\n",
       "      <th>label_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5970</td>\n",
       "      <td>fake_DALLE/DALL_E11.webp</td>\n",
       "      <td>A small orange airplane prepares to take off.</td>\n",
       "      <td>dall-E3</td>\n",
       "      <td>fake</td>\n",
       "      <td>./data\\fake_DALLE/DALL_E11.webp</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4757</td>\n",
       "      <td>fake_IMAGEN/806c023ce8b7e2b0bc95ebc9ae7739ed.png</td>\n",
       "      <td>hyperrealism woman wearing a black robe holdin...</td>\n",
       "      <td>im</td>\n",
       "      <td>fake</td>\n",
       "      <td>./data\\fake_IMAGEN/806c023ce8b7e2b0bc95ebc9ae7...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4450</td>\n",
       "      <td>fake_IMAGEN/c51379554ca11eafb0d8d7f6ad6eb0c5.png</td>\n",
       "      <td>The square coaster was next to the circular gl...</td>\n",
       "      <td>im</td>\n",
       "      <td>fake</td>\n",
       "      <td>./data\\fake_IMAGEN/c51379554ca11eafb0d8d7f6ad6...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1709</td>\n",
       "      <td>fake_SD/Image_sd2 34.jpg</td>\n",
       "      <td>A man brushing his child's teeth while the ch...</td>\n",
       "      <td>sd</td>\n",
       "      <td>fake</td>\n",
       "      <td>./data\\fake_SD/Image_sd2 34.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2698</td>\n",
       "      <td>fake_IMAGEN/image_fx_a_man_is_sitting_at_a_tab...</td>\n",
       "      <td>A man is sitting at a table with a drink</td>\n",
       "      <td>im</td>\n",
       "      <td>fake</td>\n",
       "      <td>./data\\fake_IMAGEN/image_fx_a_man_is_sitting_a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id                                         image_file  \\\n",
       "0  5970                           fake_DALLE/DALL_E11.webp   \n",
       "1  4757   fake_IMAGEN/806c023ce8b7e2b0bc95ebc9ae7739ed.png   \n",
       "2  4450   fake_IMAGEN/c51379554ca11eafb0d8d7f6ad6eb0c5.png   \n",
       "3  1709                           fake_SD/Image_sd2 34.jpg   \n",
       "4  2698  fake_IMAGEN/image_fx_a_man_is_sitting_at_a_tab...   \n",
       "\n",
       "                                             prompts platform status  \\\n",
       "0      A small orange airplane prepares to take off.  dall-E3   fake   \n",
       "1  hyperrealism woman wearing a black robe holdin...       im   fake   \n",
       "2  The square coaster was next to the circular gl...       im   fake   \n",
       "3   A man brushing his child's teeth while the ch...       sd   fake   \n",
       "4           A man is sitting at a table with a drink       im   fake   \n",
       "\n",
       "                                           full_path  label_id  \n",
       "0                    ./data\\fake_DALLE/DALL_E11.webp         0  \n",
       "1  ./data\\fake_IMAGEN/806c023ce8b7e2b0bc95ebc9ae7...         1  \n",
       "2  ./data\\fake_IMAGEN/c51379554ca11eafb0d8d7f6ad6...         1  \n",
       "3                    ./data\\fake_SD/Image_sd2 34.jpg         2  \n",
       "4  ./data\\fake_IMAGEN/image_fx_a_man_is_sitting_a...         1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- Load and prepare metadata ---\n",
    "BASE_DIR = './data'\n",
    "METADATA_FILE = os.path.join(BASE_DIR, 'metadata.json')\n",
    "MODEL_CHECKPOINT = 'microsoft/swinv2-small-patch4-window8-256'\n",
    "\n",
    "print(f'Loading metadata from: {METADATA_FILE}')\n",
    "df = pd.read_json(METADATA_FILE)\n",
    "\n",
    "# Flatten image_file if nested lists are present\n",
    "if isinstance(df['image_file'].iloc[0], list):\n",
    "    df['image_file'] = df['image_file'].str[0]\n",
    "\n",
    "# Build absolute/full image paths\n",
    "df['full_path'] = df['image_file'].apply(lambda x: os.path.join(BASE_DIR, x))\n",
    "\n",
    "# Filter to fake images and require platform\n",
    "df = df[df['status'] == 'fake'].copy()\n",
    "if 'platform' not in df.columns:\n",
    "    raise ValueError(\"metadata.json must contain a 'platform' key for fake images.\")\n",
    "df = df[~df['platform'].isna()].copy()\n",
    "\n",
    "# Build label vocab from platform values\n",
    "label_names = sorted(df['platform'].unique().tolist())\n",
    "label2id = {l: i for i, l in enumerate(label_names)}\n",
    "id2label = {i: l for l, i in label2id.items()}\n",
    "df['label_id'] = df['platform'].map(label2id).astype(int)\n",
    "\n",
    "# Split\n",
    "train_df, val_df = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df['label_id']\n",
    ")\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_df = val_df.reset_index(drop=True)\n",
    "\n",
    "print('Classes (platforms):', label_names)\n",
    "print('Total:', len(df), 'Train:', len(train_df), 'Val:', len(val_df))\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a55734e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets -> train: 5687 val: 1422\n"
     ]
    }
   ],
   "source": [
    "# --- Processor and Datasets (Swin + ResNet branches) ---\n",
    "processor = AutoImageProcessor.from_pretrained(MODEL_CHECKPOINT)\n",
    "target = processor.size['height'] if isinstance(processor.size, dict) and 'height' in processor.size else 256\n",
    "\n",
    "# Train-time augmentations on PIL images\n",
    "train_augs = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(target),\n",
    "    transforms.RandomHorizontalFlip(0.5),\n",
    "    transforms.ColorJitter(0.1, 0.1, 0.1),\n",
    "    transforms.RandomRotation(10),\n",
    "])\n",
    "\n",
    "# ResNet preprocessing (ImageNet normalization)\n",
    "imagenet_mean = [0.485, 0.456, 0.406]\n",
    "imagenet_std = [0.229, 0.224, 0.225]\n",
    "resnet_base_transforms = transforms.Compose([\n",
    "    transforms.Resize(target),\n",
    "    transforms.CenterCrop(target),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std),\n",
    "])\n",
    "\n",
    "class HybridMultiDataset(Dataset):\n",
    "    def __init__(self, df, processor, transforms=None):\n",
    "        self.df = df\n",
    "        self.processor = processor\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img_path = row['full_path']\n",
    "        label_id = int(row['label_id'])\n",
    "        try:\n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "        except FileNotFoundError:\n",
    "            return self.__getitem__((idx + 1) % len(self))\n",
    "\n",
    "        pil_img = self.transforms(image) if self.transforms is not None else image\n",
    "\n",
    "        # SwinV2 branch (processor handles normalization)\n",
    "        swin_inputs = self.processor(images=pil_img, return_tensors='pt')\n",
    "        pixel_values = swin_inputs['pixel_values'].squeeze(0)\n",
    "\n",
    "        # ResNet branch (ImageNet normalized tensor)\n",
    "        resnet_pixel_values = resnet_base_transforms(pil_img)\n",
    "\n",
    "        return {\n",
    "            'pixel_values': pixel_values,\n",
    "            'resnet_pixel_values': resnet_pixel_values,\n",
    "            'labels': torch.tensor(label_id, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "train_dataset = HybridMultiDataset(train_df, processor, transforms=train_augs)\n",
    "val_dataset = HybridMultiDataset(val_df, processor, transforms=None)\n",
    "print('Datasets -> train:', len(train_dataset), 'val:', len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebdfe93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Hybrid Model (ResNet18 + SwinV2 Small) ---\n",
    "class ResNetSwinClassifier(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super().__init__()\n",
    "        # ResNet50\n",
    "        try:\n",
    "            weights = models.ResNet50_Weights.DEFAULT\n",
    "            self.resnet = models.resnet50(weights=weights)\n",
    "        except AttributeError:\n",
    "            self.resnet = models.resnet50(pretrained=True)\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        resnet_out_dim = 2048\n",
    "\n",
    "        # SwinV2 (feature extractor)\n",
    "        self.swin = Swinv2Model.from_pretrained('microsoft/swinv2-small-patch4-window8-256')\n",
    "        swin_out_dim = self.swin.config.hidden_size\n",
    "\n",
    "        # Fusion head\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(resnet_out_dim + swin_out_dim, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_labels),\n",
    "        )\n",
    "\n",
    "    def forward(self, pixel_values=None, resnet_pixel_values=None, labels=None):\n",
    "        # Swin features\n",
    "        swin_outputs = self.swin(pixel_values=pixel_values)\n",
    "        swin_feat = getattr(swin_outputs, 'pooler_output', None)\n",
    "        if swin_feat is None:\n",
    "            swin_feat = swin_outputs.last_hidden_state.mean(dim=1)\n",
    "\n",
    "        # ResNet features\n",
    "        resnet_feat = self.resnet(resnet_pixel_values)\n",
    "\n",
    "        # Fuse\n",
    "        combined = torch.cat([resnet_feat, swin_feat], dim=1)\n",
    "        logits = self.classifier(combined)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss = nn.CrossEntropyLoss()(logits, labels)\n",
    "        return {'loss': loss, 'logits': logits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad18d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Metrics ---\n",
    "metric = evaluate.load('accuracy')\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=preds, references=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c814b2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- TrainingArguments ---\n",
    "use_fp16 = torch.cuda.is_available()\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./hybrid-multiclass50',\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=16,\n",
    "    eval_strategy='epoch',\n",
    "    save_strategy='epoch',\n",
    "    num_train_epochs=15,\n",
    "    fp16=use_fp16,\n",
    "    learning_rate=2e-5,\n",
    "    logging_dir='./logs',\n",
    "    logging_strategy='steps',\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model='accuracy',\n",
    "    remove_unused_columns=False,\n",
    "    report_to='none',\n",
    "    dataloader_pin_memory=torch.cuda.is_available(),\n",
    "    dataloader_num_workers=0,\n",
    "    disable_tqdm=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed37916d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\komal\\AppData\\Local\\Temp\\ipykernel_30084\\2001588234.py:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    }
   ],
   "source": [
    "# --- Model + Trainer ---\n",
    "model = ResNetSwinClassifier(num_labels=len(label_names))\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=processor,\n",
    "    compute_metrics=compute_metrics,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b4c93aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: {0: 'dall-E3', 1: 'im', 2: 'sd'}\n",
      "ðŸš€ Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='9243' max='10665' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 9243/10665 1:43:54 < 15:59, 1.48 it/s, Epoch 13/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.386600</td>\n",
       "      <td>0.543783</td>\n",
       "      <td>0.797468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.171900</td>\n",
       "      <td>0.344063</td>\n",
       "      <td>0.881857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.368000</td>\n",
       "      <td>0.457172</td>\n",
       "      <td>0.876231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.294600</td>\n",
       "      <td>0.374140</td>\n",
       "      <td>0.892405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.242700</td>\n",
       "      <td>0.361702</td>\n",
       "      <td>0.912096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.186300</td>\n",
       "      <td>0.957632</td>\n",
       "      <td>0.811533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.310700</td>\n",
       "      <td>0.678007</td>\n",
       "      <td>0.875527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.073900</td>\n",
       "      <td>0.425549</td>\n",
       "      <td>0.921238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.302300</td>\n",
       "      <td>0.697281</td>\n",
       "      <td>0.883966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.346600</td>\n",
       "      <td>0.708805</td>\n",
       "      <td>0.889592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.036800</td>\n",
       "      <td>0.672538</td>\n",
       "      <td>0.897328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.014600</td>\n",
       "      <td>0.621250</td>\n",
       "      <td>0.906470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.157200</td>\n",
       "      <td>0.584235</td>\n",
       "      <td>0.911392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training finished!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='89' max='89' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [89/89 01:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation metrics: {'eval_loss': 0.4255494773387909, 'eval_accuracy': 0.9212376933895922, 'eval_runtime': 64.4528, 'eval_samples_per_second': 22.063, 'eval_steps_per_second': 1.381, 'epoch': 13.0}\n",
      "Best checkpoint: ./hybrid-multiclass50\\checkpoint-5688\n",
      "Saved model to ./best-model-hybrid-multiclass50\n"
     ]
    }
   ],
   "source": [
    "print('Classes:', id2label)\n",
    "print('ðŸš€ Starting training...')\n",
    "_ = trainer.train()\n",
    "print('âœ… Training finished!')\n",
    "\n",
    "metrics = trainer.evaluate()\n",
    "print('Validation metrics:', metrics)\n",
    "\n",
    "best_ckpt = getattr(trainer.state, 'best_model_checkpoint', None)\n",
    "save_dir = './best-model-hybrid-multiclass50'\n",
    "if best_ckpt:\n",
    "    print('Best checkpoint:', best_ckpt)\n",
    "trainer.save_model(save_dir)\n",
    "print('Saved model to', save_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad370d3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_train",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
